{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import os\n",
    "import glob\n",
    "import torch\n",
    "from tqdm import tqdm\n",
    "from recbole.config import Config\n",
    "from recbole.data import create_dataset, data_preparation\n",
    "# from recbole.quick_start import load_data_and_model\n",
    "from recbole.utils.case_study import full_sort_scores, full_sort_topk\n",
    "from recbole.utils import init_seed, get_model, get_trainer\n",
    "from recbole.data.interaction import Interaction\n",
    "from recbole.evaluator import Evaluator\n",
    "from recbole.evaluator.collector import DataStruct\n",
    "from tqdm import tqdm\n",
    "from collections import defaultdict\n",
    "import time\n",
    "import warnings\n",
    "\n",
    "warnings.filterwarnings('ignore')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "from utils.utils import (\n",
    "    latest_checkpoint,\n",
    "    create_ground_truth,\n",
    "    calculate_recall_at_k,\n",
    "    min_max_scale_excluding_inf,\n",
    "    get_top_k_indices\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "def load_data_and_model(model_file):\n",
    "\n",
    "    checkpoint = torch.load(model_file)\n",
    "    config = checkpoint[\"config\"]\n",
    "    init_seed(config[\"seed\"], config[\"reproducibility\"])\n",
    "\n",
    "    dataset = create_dataset(config)\n",
    "    train_data, valid_data, test_data = data_preparation(config, dataset)\n",
    "\n",
    "    init_seed(config[\"seed\"], config[\"reproducibility\"])\n",
    "    model = get_model(config[\"model\"])(config, train_data._dataset).to(config[\"device\"])\n",
    "    model.load_state_dict(checkpoint[\"state_dict\"])\n",
    "    model.load_other_parameter(checkpoint.get(\"other_parameter\"))\n",
    "\n",
    "    return config, model, dataset, train_data, valid_data, test_data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "model_info_list = [\n",
    "    # General\n",
    "    {'model': 'EASE', 'model_type': 'general'},\n",
    "    {'model': 'ADMMSLIM', 'model_type': 'general'},\n",
    "    {'model': 'CDAE', 'model_type': 'general'},\n",
    "    # {'model': 'SLIMElastic', 'model_type': 'general'},\n",
    "    {'model': 'RecVAE', 'model_type': 'general'},\n",
    "    {'model': 'MultiVAE', 'model_type': 'general'},\n",
    "    {'model': 'MultiDAE', 'model_type': 'general'},\n",
    "    {'model': 'LightGCN', 'model_type': 'general'},\n",
    "    \n",
    "    # Context\n",
    "    {'model': 'DCNV2', 'model_type': 'context'},\n",
    "    {'model': 'DeepFM', 'model_type': 'context'},\n",
    "\n",
    "    # Sequential\n",
    "    {'model': 'BERT4Rec', 'model_type': 'sequential'},\n",
    "    {'model': 'GRU4Rec', 'model_type': 'sequential'},\n",
    "    {'model': 'GRU4RecF', 'model_type': 'sequential'},\n",
    "    {'model': 'SASRec', 'model_type': 'sequential'},\n",
    "    # {'model': 'SASRecF', 'model_type': 'sequential'},\n",
    "]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "EASE: model/saved/EASE/EASE-Nov-26-2024_10-46-47.pth\n",
      "ADMMSLIM: model/saved/ADMMSLIM/ADMMSLIM-Nov-26-2024_15-27-37.pth\n",
      "CDAE: model/saved/CDAE/CDAE-Nov-26-2024_12-29-41.pth\n",
      "RecVAE: model/saved/RecVAE/RecVAE-Nov-26-2024_12-41-37.pth\n",
      "MultiVAE: model/saved/MultiVAE/MultiVAE-Nov-25-2024_17-32-14.pth\n",
      "MultiDAE: model/saved/MultiDAE/MultiDAE-Nov-26-2024_15-01-39.pth\n",
      "LightGCN: model/saved/LightGCN/LightGCN-Nov-26-2024_01-56-18.pth\n",
      "DCNV2: model/saved/DCNV2/DCNV2-Nov-25-2024_22-44-55.pth\n",
      "DeepFM: model/saved/DeepFM/DeepFM-Nov-25-2024_20-57-38.pth\n",
      "BERT4Rec: model/saved/BERT4Rec/BERT4Rec-Nov-27-2024_23-39-59.pth\n",
      "GRU4Rec: model/saved/GRU4Rec/GRU4Rec-Nov-27-2024_14-03-49.pth\n",
      "GRU4RecF: model/saved/GRU4RecF/GRU4RecF-Nov-28-2024_01-07-18.pth\n",
      "SASRec: model/saved/SASRec/SASRec-Nov-27-2024_19-27-55.pth\n"
     ]
    }
   ],
   "source": [
    "configs = []\n",
    "checkpoints = []\n",
    "for i in range(len(model_info_list)):\n",
    "    model_name = model_info_list[i]['model']\n",
    "    checkpoint_dir = f'model/saved/{model_name}'\n",
    "    checkpoint_pattern = os.path.join(checkpoint_dir, f\"{model_name}-*.pth\")\n",
    "    checkpoint_files = glob.glob(checkpoint_pattern)\n",
    "    # 최신 체크포인트 파일 선택\n",
    "    checkpoint_path = max(checkpoint_files, key=os.path.getmtime)\n",
    "    print(f\"{model_name}: {checkpoint_path}\")\n",
    "    checkpoints.append(checkpoint_path)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 오류 발생 시:\n",
    "\n",
    "- `numpy` 최신 버전을 사용할 경우, `np.long` 자료형이 더 이상 지원되지 않으므로, `numpy` 버전을 낮추거나 RecBole에서 `np.long`을 사용하는 부분을 수정해야 함\n",
    "- 여기서는 RecBole의 `/lib/python3.11/site-packages/recbole/model/layers.py` 부분과, `lib/python3.11/site-packages/recbole/model/abstract_recommender.py`에 등장하는 `np.long`을 `np.int64`로 수정하여 오류를 해결함"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading EASE: 63.2947s\n",
      "Loading ADMMSLIM: 590.0921s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Max value of user's history interaction records has reached 42.34723854289072% of the total.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading CDAE: 63.7542s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Max value of user's history interaction records has reached 42.34723854289072% of the total.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading RecVAE: 76.2795s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Max value of user's history interaction records has reached 42.34723854289072% of the total.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading MultiVAE: 76.3642s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Max value of user's history interaction records has reached 42.34723854289072% of the total.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading MultiDAE: 79.5287s\n",
      "Loading LightGCN: 81.5287s\n",
      "Loading DCNV2: 76.4887s\n",
      "Loading DeepFM: 85.3699s\n"
     ]
    },
    {
     "ename": "RuntimeError",
     "evalue": "PytorchStreamReader failed reading zip archive: failed finding central directory",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mRuntimeError\u001b[0m                              Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[6], line 9\u001b[0m\n\u001b[1;32m      7\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m i \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mrange\u001b[39m(\u001b[38;5;28mlen\u001b[39m(model_info_list)):\n\u001b[1;32m      8\u001b[0m     start \u001b[38;5;241m=\u001b[39m time\u001b[38;5;241m.\u001b[39mtime()\n\u001b[0;32m----> 9\u001b[0m     config, model, dataset, train_data, valid_data, _ \u001b[38;5;241m=\u001b[39m \u001b[43mload_data_and_model\u001b[49m\u001b[43m(\u001b[49m\u001b[43mcheckpoints\u001b[49m\u001b[43m[\u001b[49m\u001b[43mi\u001b[49m\u001b[43m]\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     10\u001b[0m     \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mLoading \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mmodel_info_list[i][\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mmodel\u001b[39m\u001b[38;5;124m'\u001b[39m]\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m: \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mtime\u001b[38;5;241m.\u001b[39mtime()\u001b[38;5;241m-\u001b[39mstart\u001b[38;5;132;01m:\u001b[39;00m\u001b[38;5;124m.4f\u001b[39m\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124ms\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[1;32m     11\u001b[0m     configs\u001b[38;5;241m.\u001b[39mappend(config)\n",
      "Cell \u001b[0;32mIn[3], line 3\u001b[0m, in \u001b[0;36mload_data_and_model\u001b[0;34m(model_file)\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mload_data_and_model\u001b[39m(model_file):\n\u001b[0;32m----> 3\u001b[0m     checkpoint \u001b[38;5;241m=\u001b[39m \u001b[43mtorch\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mload\u001b[49m\u001b[43m(\u001b[49m\u001b[43mmodel_file\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m      4\u001b[0m     config \u001b[38;5;241m=\u001b[39m checkpoint[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mconfig\u001b[39m\u001b[38;5;124m\"\u001b[39m]\n\u001b[1;32m      5\u001b[0m     init_seed(config[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mseed\u001b[39m\u001b[38;5;124m\"\u001b[39m], config[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mreproducibility\u001b[39m\u001b[38;5;124m\"\u001b[39m])\n",
      "File \u001b[0;32m~/level2-recsys-movierecommendation-recsys-01-lv3/.venv/lib/python3.11/site-packages/torch/serialization.py:1326\u001b[0m, in \u001b[0;36mload\u001b[0;34m(f, map_location, pickle_module, weights_only, mmap, **pickle_load_args)\u001b[0m\n\u001b[1;32m   1324\u001b[0m orig_position \u001b[38;5;241m=\u001b[39m opened_file\u001b[38;5;241m.\u001b[39mtell()\n\u001b[1;32m   1325\u001b[0m overall_storage \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[0;32m-> 1326\u001b[0m \u001b[38;5;28;01mwith\u001b[39;00m \u001b[43m_open_zipfile_reader\u001b[49m\u001b[43m(\u001b[49m\u001b[43mopened_file\u001b[49m\u001b[43m)\u001b[49m \u001b[38;5;28;01mas\u001b[39;00m opened_zipfile:\n\u001b[1;32m   1327\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m _is_torchscript_zip(opened_zipfile):\n\u001b[1;32m   1328\u001b[0m         warnings\u001b[38;5;241m.\u001b[39mwarn(\n\u001b[1;32m   1329\u001b[0m             \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mtorch.load\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124m received a zip file that looks like a TorchScript archive\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m   1330\u001b[0m             \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m dispatching to \u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mtorch.jit.load\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124m (call \u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mtorch.jit.load\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124m directly to\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m   1331\u001b[0m             \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m silence this warning)\u001b[39m\u001b[38;5;124m\"\u001b[39m,\n\u001b[1;32m   1332\u001b[0m             \u001b[38;5;167;01mUserWarning\u001b[39;00m,\n\u001b[1;32m   1333\u001b[0m         )\n",
      "File \u001b[0;32m~/level2-recsys-movierecommendation-recsys-01-lv3/.venv/lib/python3.11/site-packages/torch/serialization.py:671\u001b[0m, in \u001b[0;36m_open_zipfile_reader.__init__\u001b[0;34m(self, name_or_buffer)\u001b[0m\n\u001b[1;32m    670\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21m__init__\u001b[39m(\u001b[38;5;28mself\u001b[39m, name_or_buffer) \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m>\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[0;32m--> 671\u001b[0m     \u001b[38;5;28msuper\u001b[39m()\u001b[38;5;241m.\u001b[39m\u001b[38;5;21m__init__\u001b[39m(\u001b[43mtorch\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_C\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mPyTorchFileReader\u001b[49m\u001b[43m(\u001b[49m\u001b[43mname_or_buffer\u001b[49m\u001b[43m)\u001b[49m)\n",
      "\u001b[0;31mRuntimeError\u001b[0m: PytorchStreamReader failed reading zip archive: failed finding central directory"
     ]
    }
   ],
   "source": [
    "configs = []\n",
    "models = []\n",
    "datasets = []\n",
    "train_datasets = []\n",
    "valid_datasets = []\n",
    "\n",
    "for i in range(len(model_info_list)):\n",
    "    start = time.time()\n",
    "    config, model, dataset, train_data, valid_data, _ = load_data_and_model(checkpoints[i])\n",
    "    print(f\"Loading {model_info_list[i]['model']}: {time.time()-start:.4f}s\")\n",
    "    configs.append(config)\n",
    "    models.append(model)\n",
    "    datasets.append(dataset)\n",
    "    train_datasets.append(train_data)\n",
    "    valid_datasets.append(valid_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# temp_save_files = torch.load('model/temp1_saved_files.pth')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# configs = temp_save_files2['configs']\n",
    "# models = temp_save_files2['models']\n",
    "# datasets = temp_save_files2['datasets']\n",
    "# train_datasets = temp_save_files2['train_datasets']\n",
    "# valid_datasets = temp_save_files2['valid_datasets']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading BERT4Rec: 209.8402s\n",
      "Loading GRU4Rec: 211.2989s\n",
      "Loading GRU4RecF: 216.2147s\n",
      "Loading SASRec: 201.8457s\n"
     ]
    }
   ],
   "source": [
    "for i in range(9, len(model_info_list)):\n",
    "    start = time.time()\n",
    "    config, model, dataset, train_data, valid_data, _ = load_data_and_model(checkpoints[i])\n",
    "    print(f\"Loading {model_info_list[i]['model']}: {time.time()-start:.4f}s\")\n",
    "    configs.append(config)\n",
    "    models.append(model)\n",
    "    datasets.append(dataset)\n",
    "    train_datasets.append(train_data)\n",
    "    valid_datasets.append(valid_data)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 중간 저장\n",
    "\n",
    "- `load_data_and_model`이 시간이 오래 걸림 \n",
    "    - EASE, ADMMSLIM 등 `TRADITIONAL` 모델의 경우 `__init__` 메서드에서 학습을 하기 때문\n",
    "    - 그 외에도 `DataLoader`를 각 모델마다 불러오는 과정이 시간을 꽤나 잡아먹음\n",
    "- 이 과정을 한 번만 수행한 다음, 모두 딕셔너리로 만들어 `.pth` 파일로 저장하는 방식을 취함"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "temp_save_files = {\n",
    "    'configs': configs,\n",
    "    'models': models,\n",
    "    'datasets': datasets,\n",
    "    'train_datasets': train_datasets,\n",
    "    'valid_datasets': valid_datasets\n",
    "}\n",
    "save_path = 'model/temp_saved_files.pth'\n",
    "torch.save(temp_save_files, save_path, pickle_protocol=4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import gc\n",
    "gc.collect()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 1960/1960 [00:45<00:00, 43.20it/s]\n",
      "100%|██████████| 1960/1960 [01:54<00:00, 17.13it/s]\n",
      "100%|██████████| 1960/1960 [00:09<00:00, 206.77it/s]\n",
      "100%|██████████| 1960/1960 [00:09<00:00, 211.85it/s]\n",
      "100%|██████████| 1960/1960 [00:08<00:00, 220.68it/s]\n",
      "100%|██████████| 1960/1960 [00:08<00:00, 218.66it/s]\n",
      "100%|██████████| 1960/1960 [00:03<00:00, 604.74it/s]\n",
      "100%|██████████| 1960/1960 [01:09<00:00, 28.17it/s]\n",
      "100%|██████████| 1960/1960 [00:33<00:00, 59.23it/s]\n",
      "100%|██████████| 1960/1960 [00:34<00:00, 56.89it/s]\n",
      "100%|██████████| 1960/1960 [00:26<00:00, 74.40it/s]\n",
      "100%|██████████| 1960/1960 [00:28<00:00, 68.48it/s]\n",
      "100%|██████████| 1960/1960 [00:29<00:00, 66.90it/s]\n",
      "100%|██████████| 13/13 [07:03<00:00, 32.57s/it]\n"
     ]
    }
   ],
   "source": [
    "sample_submission = pd.read_csv(os.path.join(config['eval_path'], 'sample_submission.csv'))\n",
    "sample_submission.columns = ['user_id', 'item_id']\n",
    "test_users = sample_submission['user_id'].unique().tolist()\n",
    "test_users = [str(user) for user in test_users]\n",
    "\n",
    "model_recommendations = []\n",
    "for full_dataset, valid_data, best_model in tqdm(zip(datasets, valid_datasets, models), total=len(models)):\n",
    "\n",
    "    uid_series = full_dataset.token2id(full_dataset.uid_field, test_users)\n",
    "\n",
    "    batch_size = 16\n",
    "    recommended_df = pd.DataFrame(columns=['user', 'item'])\n",
    "    for i in tqdm(range(0, len(uid_series), batch_size)):\n",
    "        batch_indices = uid_series[i:i+batch_size]\n",
    "        batch_users = test_users[i:i+batch_size]\n",
    "\n",
    "        topk_iid_list_batch = full_sort_topk(batch_indices, best_model, valid_data, k=20, device=config['device'])\n",
    "        last_topk_iid_list = topk_iid_list_batch.indices\n",
    "        recommended_item_list = full_dataset.id2token(full_dataset.iid_field, last_topk_iid_list.cpu()).tolist()\n",
    "        temp_df = pd.DataFrame({'user': batch_users, 'item': recommended_item_list})\n",
    "        recommended_df = pd.concat([recommended_df, temp_df], ignore_index=True)\n",
    "\n",
    "    recommended_df = recommended_df.explode('item').reset_index(drop=True)\n",
    "    model_recommendations.append(recommended_df)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Inference 결과 저장\n",
    "\n",
    "- Hard Voting에 사용할 후보 모델들의 inference 결과를 모두 `.pth` 파일로 저장\n",
    "- Hard Voting에서는 이 후보 inference를 가지고 수행하면 됨"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "temp_file = {\n",
    "    'model_recommendations': model_recommendations\n",
    "}\n",
    "save_path = 'data/output/Ensemble/Ensemble_Candidates.pth'\n",
    "torch.save(temp_file, save_path, pickle_protocol=4)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# output별 유사도 측정"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from itertools import combinations\n",
    "\n",
    "def count_similiarity(df1, df2):\n",
    "    df = pd.concat([df1,df2])\n",
    "    df = df.groupby(['user','item']).size().reset_index(name='counts')\n",
    "    df = df[df['counts'] > 1]\n",
    "    return len(df) / len(df1) * 100\n",
    "\n",
    "index_combinations = list(combinations(range(len(model_recommendations)), 2))\n",
    "\n",
    "similarity_matrix = pd.DataFrame(\n",
    "    np.zeros((len(models), len(models))), \n",
    "    index=[model['model'] for model in model_info_list], \n",
    "    columns=[model['model'] for model in model_info_list]\n",
    ")\n",
    "\n",
    "for i, j in index_combinations:\n",
    "    df1 = model_recommendations[i]\n",
    "    df2 = model_recommendations[j]\n",
    "    sim = count_similiarity(df1, df2)\n",
    "    df1_name = model_info_list[i]['model']\n",
    "    df2_name = model_info_list[j]['model']\n",
    "    # print(f'{df1_name} and {df2_name}: {sim:.2f}% similarity')\n",
    "    \n",
    "    similarity_matrix.loc[df1_name, df2_name] = sim\n",
    "    similarity_matrix.loc[df2_name, df1_name] = sim"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [],
   "source": [
    "pd.options.display.float_format = '{:.2f}'.format"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>EASE</th>\n",
       "      <th>ADMMSLIM</th>\n",
       "      <th>CDAE</th>\n",
       "      <th>RecVAE</th>\n",
       "      <th>MultiVAE</th>\n",
       "      <th>MultiDAE</th>\n",
       "      <th>LightGCN</th>\n",
       "      <th>DCNV2</th>\n",
       "      <th>DeepFM</th>\n",
       "      <th>BERT4Rec</th>\n",
       "      <th>GRU4Rec</th>\n",
       "      <th>GRU4RecF</th>\n",
       "      <th>SASRec</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>EASE</th>\n",
       "      <td>0.00</td>\n",
       "      <td>74.06</td>\n",
       "      <td>59.21</td>\n",
       "      <td>55.39</td>\n",
       "      <td>52.00</td>\n",
       "      <td>51.32</td>\n",
       "      <td>48.58</td>\n",
       "      <td>53.23</td>\n",
       "      <td>45.19</td>\n",
       "      <td>7.53</td>\n",
       "      <td>8.15</td>\n",
       "      <td>8.27</td>\n",
       "      <td>7.15</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>ADMMSLIM</th>\n",
       "      <td>74.06</td>\n",
       "      <td>0.00</td>\n",
       "      <td>51.67</td>\n",
       "      <td>49.84</td>\n",
       "      <td>46.07</td>\n",
       "      <td>45.38</td>\n",
       "      <td>43.85</td>\n",
       "      <td>49.40</td>\n",
       "      <td>41.05</td>\n",
       "      <td>7.25</td>\n",
       "      <td>7.77</td>\n",
       "      <td>7.96</td>\n",
       "      <td>6.93</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>CDAE</th>\n",
       "      <td>59.21</td>\n",
       "      <td>51.67</td>\n",
       "      <td>0.00</td>\n",
       "      <td>60.72</td>\n",
       "      <td>57.44</td>\n",
       "      <td>58.23</td>\n",
       "      <td>56.54</td>\n",
       "      <td>54.32</td>\n",
       "      <td>52.13</td>\n",
       "      <td>7.93</td>\n",
       "      <td>8.82</td>\n",
       "      <td>8.81</td>\n",
       "      <td>7.94</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>RecVAE</th>\n",
       "      <td>55.39</td>\n",
       "      <td>49.84</td>\n",
       "      <td>60.72</td>\n",
       "      <td>0.00</td>\n",
       "      <td>59.65</td>\n",
       "      <td>58.55</td>\n",
       "      <td>62.44</td>\n",
       "      <td>65.09</td>\n",
       "      <td>58.67</td>\n",
       "      <td>7.78</td>\n",
       "      <td>8.57</td>\n",
       "      <td>8.60</td>\n",
       "      <td>7.64</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>MultiVAE</th>\n",
       "      <td>52.00</td>\n",
       "      <td>46.07</td>\n",
       "      <td>57.44</td>\n",
       "      <td>59.65</td>\n",
       "      <td>0.00</td>\n",
       "      <td>59.12</td>\n",
       "      <td>53.18</td>\n",
       "      <td>54.72</td>\n",
       "      <td>49.47</td>\n",
       "      <td>7.67</td>\n",
       "      <td>8.32</td>\n",
       "      <td>8.33</td>\n",
       "      <td>7.47</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>MultiDAE</th>\n",
       "      <td>51.32</td>\n",
       "      <td>45.38</td>\n",
       "      <td>58.23</td>\n",
       "      <td>58.55</td>\n",
       "      <td>59.12</td>\n",
       "      <td>0.00</td>\n",
       "      <td>53.18</td>\n",
       "      <td>51.55</td>\n",
       "      <td>48.97</td>\n",
       "      <td>7.72</td>\n",
       "      <td>8.37</td>\n",
       "      <td>8.38</td>\n",
       "      <td>7.64</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>LightGCN</th>\n",
       "      <td>48.58</td>\n",
       "      <td>43.85</td>\n",
       "      <td>56.54</td>\n",
       "      <td>62.44</td>\n",
       "      <td>53.18</td>\n",
       "      <td>53.18</td>\n",
       "      <td>0.00</td>\n",
       "      <td>57.89</td>\n",
       "      <td>58.03</td>\n",
       "      <td>7.49</td>\n",
       "      <td>8.30</td>\n",
       "      <td>8.27</td>\n",
       "      <td>7.66</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>DCNV2</th>\n",
       "      <td>53.23</td>\n",
       "      <td>49.40</td>\n",
       "      <td>54.32</td>\n",
       "      <td>65.09</td>\n",
       "      <td>54.72</td>\n",
       "      <td>51.55</td>\n",
       "      <td>57.89</td>\n",
       "      <td>0.00</td>\n",
       "      <td>56.24</td>\n",
       "      <td>7.90</td>\n",
       "      <td>8.80</td>\n",
       "      <td>8.70</td>\n",
       "      <td>7.61</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>DeepFM</th>\n",
       "      <td>45.19</td>\n",
       "      <td>41.05</td>\n",
       "      <td>52.13</td>\n",
       "      <td>58.67</td>\n",
       "      <td>49.47</td>\n",
       "      <td>48.97</td>\n",
       "      <td>58.03</td>\n",
       "      <td>56.24</td>\n",
       "      <td>0.00</td>\n",
       "      <td>7.35</td>\n",
       "      <td>8.04</td>\n",
       "      <td>8.07</td>\n",
       "      <td>7.23</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>BERT4Rec</th>\n",
       "      <td>7.53</td>\n",
       "      <td>7.25</td>\n",
       "      <td>7.93</td>\n",
       "      <td>7.78</td>\n",
       "      <td>7.67</td>\n",
       "      <td>7.72</td>\n",
       "      <td>7.49</td>\n",
       "      <td>7.90</td>\n",
       "      <td>7.35</td>\n",
       "      <td>0.00</td>\n",
       "      <td>51.78</td>\n",
       "      <td>47.29</td>\n",
       "      <td>40.90</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>GRU4Rec</th>\n",
       "      <td>8.15</td>\n",
       "      <td>7.77</td>\n",
       "      <td>8.82</td>\n",
       "      <td>8.57</td>\n",
       "      <td>8.32</td>\n",
       "      <td>8.37</td>\n",
       "      <td>8.30</td>\n",
       "      <td>8.80</td>\n",
       "      <td>8.04</td>\n",
       "      <td>51.78</td>\n",
       "      <td>0.00</td>\n",
       "      <td>51.89</td>\n",
       "      <td>45.86</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>GRU4RecF</th>\n",
       "      <td>8.27</td>\n",
       "      <td>7.96</td>\n",
       "      <td>8.81</td>\n",
       "      <td>8.60</td>\n",
       "      <td>8.33</td>\n",
       "      <td>8.38</td>\n",
       "      <td>8.27</td>\n",
       "      <td>8.70</td>\n",
       "      <td>8.07</td>\n",
       "      <td>47.29</td>\n",
       "      <td>51.89</td>\n",
       "      <td>0.00</td>\n",
       "      <td>42.18</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>SASRec</th>\n",
       "      <td>7.15</td>\n",
       "      <td>6.93</td>\n",
       "      <td>7.94</td>\n",
       "      <td>7.64</td>\n",
       "      <td>7.47</td>\n",
       "      <td>7.64</td>\n",
       "      <td>7.66</td>\n",
       "      <td>7.61</td>\n",
       "      <td>7.23</td>\n",
       "      <td>40.90</td>\n",
       "      <td>45.86</td>\n",
       "      <td>42.18</td>\n",
       "      <td>0.00</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "          EASE  ADMMSLIM  CDAE  RecVAE  MultiVAE  MultiDAE  LightGCN  DCNV2  \\\n",
       "EASE      0.00     74.06 59.21   55.39     52.00     51.32     48.58  53.23   \n",
       "ADMMSLIM 74.06      0.00 51.67   49.84     46.07     45.38     43.85  49.40   \n",
       "CDAE     59.21     51.67  0.00   60.72     57.44     58.23     56.54  54.32   \n",
       "RecVAE   55.39     49.84 60.72    0.00     59.65     58.55     62.44  65.09   \n",
       "MultiVAE 52.00     46.07 57.44   59.65      0.00     59.12     53.18  54.72   \n",
       "MultiDAE 51.32     45.38 58.23   58.55     59.12      0.00     53.18  51.55   \n",
       "LightGCN 48.58     43.85 56.54   62.44     53.18     53.18      0.00  57.89   \n",
       "DCNV2    53.23     49.40 54.32   65.09     54.72     51.55     57.89   0.00   \n",
       "DeepFM   45.19     41.05 52.13   58.67     49.47     48.97     58.03  56.24   \n",
       "BERT4Rec  7.53      7.25  7.93    7.78      7.67      7.72      7.49   7.90   \n",
       "GRU4Rec   8.15      7.77  8.82    8.57      8.32      8.37      8.30   8.80   \n",
       "GRU4RecF  8.27      7.96  8.81    8.60      8.33      8.38      8.27   8.70   \n",
       "SASRec    7.15      6.93  7.94    7.64      7.47      7.64      7.66   7.61   \n",
       "\n",
       "          DeepFM  BERT4Rec  GRU4Rec  GRU4RecF  SASRec  \n",
       "EASE       45.19      7.53     8.15      8.27    7.15  \n",
       "ADMMSLIM   41.05      7.25     7.77      7.96    6.93  \n",
       "CDAE       52.13      7.93     8.82      8.81    7.94  \n",
       "RecVAE     58.67      7.78     8.57      8.60    7.64  \n",
       "MultiVAE   49.47      7.67     8.32      8.33    7.47  \n",
       "MultiDAE   48.97      7.72     8.37      8.38    7.64  \n",
       "LightGCN   58.03      7.49     8.30      8.27    7.66  \n",
       "DCNV2      56.24      7.90     8.80      8.70    7.61  \n",
       "DeepFM      0.00      7.35     8.04      8.07    7.23  \n",
       "BERT4Rec    7.35      0.00    51.78     47.29   40.90  \n",
       "GRU4Rec     8.04     51.78     0.00     51.89   45.86  \n",
       "GRU4RecF    8.07     47.29    51.89      0.00   42.18  \n",
       "SASRec      7.23     40.90    45.86     42.18    0.00  "
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "display(similarity_matrix)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 모델 가중치 + 랭킹 가중치"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 154,
   "metadata": {},
   "outputs": [],
   "source": [
    "weights = [\n",
    "    # General\n",
    "    {'model': 'EASE',     'weight': 1},     #0   0.2366\n",
    "    {'model': 'ADMMSLIM', 'weight': 1},     #1   0.2309\n",
    "    {'model': 'CDAE',     'weight': 1},     #2   0.2203\n",
    "    {'model': 'RecVAE',   'weight': 1},     #3   0.2048\n",
    "    # {'model': 'MultiVAE', 'weight': 1},     #4   0.2016\n",
    "    # {'model': 'MultiDAE', 'weight': 1},     #5   0.2013\n",
    "    # {'model': 'LightGCN', 'weight': 1},     #6   0.1896\n",
    "    \n",
    "    # Context\n",
    "    # {'model': 'DCNV2',    'weight': 1},     #7   0.1937\n",
    "    # {'model': 'DeepFM',   'weight': 1},     #8   0.1785\n",
    "\n",
    "    # Sequential\n",
    "    {'model': 'BERT4Rec', 'weight': 0.3},     #9   0.1847\n",
    "    {'model': 'GRU4Rec',  'weight': 0.3},     #10  0.1437\n",
    "    {'model': 'GRU4RecF', 'weight': 0.3},     #11  0.1567\n",
    "    # {'model': 'SASRec',   'weight': 1},     #12  0.1161\n",
    "]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 100,
   "metadata": {},
   "outputs": [],
   "source": [
    "for i in range(len(model_recommendations)):\n",
    "    model_recommendations[i]['user'] = model_recommendations[i]['user'].astype(int)\n",
    "    model_recommendations[i]['item'] = model_recommendations[i]['item'].astype(int)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 155,
   "metadata": {},
   "outputs": [],
   "source": [
    "# rec_results = model_recommendations[0:4] + model_recommendations[9:11]\n",
    "rec_results = model_recommendations[0:4] + model_recommendations[9:12]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 156,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Calculating weighted recommendations with rank aggregation...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 7/7 [04:37<00:00, 39.68s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Generating top@10 recommendations for each user...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 31360/31360 [00:00<00:00, 42245.32it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Final recommendations:\n",
      "          user   item\n",
      "0           11   4886\n",
      "1           11   8961\n",
      "2           11   4370\n",
      "3           11      2\n",
      "4           11  32587\n",
      "...        ...    ...\n",
      "313595  138493    110\n",
      "313596  138493   2762\n",
      "313597  138493  32587\n",
      "313598  138493  48394\n",
      "313599  138493   2174\n",
      "\n",
      "[313600 rows x 2 columns]\n"
     ]
    }
   ],
   "source": [
    "# 추천 결과를 저장할 딕셔너리 {user_id: {item_id: weighted_score}}\n",
    "weighted_recommendations = defaultdict(lambda: defaultdict(float))\n",
    "\n",
    "# 가중 합 계산 (Rank Aggregation 반영)\n",
    "print(\"Calculating weighted recommendations with rank aggregation...\")\n",
    "for model_idx, df in tqdm(enumerate(rec_results), total=len(rec_results)):\n",
    "    weight = weights[model_idx]['weight']\n",
    "    grouped = df.groupby(\"user\")\n",
    "    \n",
    "    # 각 사용자별로 순위를 기반으로 점수 계산\n",
    "    for user, group in grouped:\n",
    "        # 아이템별 순위를 계산\n",
    "        group[\"rank\"] = range(1, len(group) + 1)\n",
    "        \n",
    "        # 순위를 점수에 반영 (역순위 사용: 높은 순위 -> 높은 점수)\n",
    "        for _, row in group.iterrows():\n",
    "            item = row[\"item\"]\n",
    "            rank = row[\"rank\"]\n",
    "            # 점수 계산: 모델 가중치 + 역순위 가중치\n",
    "            rank_weight = 1 / (rank+60)  # 예: 1등 = 1, 2등 = 0.5, ...\n",
    "            weighted_recommendations[user][item] += weight * rank_weight\n",
    "\n",
    "# top@10 계산 및 DataFrame 생성\n",
    "top_k = 10\n",
    "recommendation_list = []\n",
    "\n",
    "print(\"\\nGenerating top@10 recommendations for each user...\")\n",
    "for user, item_scores in tqdm(weighted_recommendations.items(), total=len(weighted_recommendations)):\n",
    "    # 아이템별 점수를 기준으로 정렬하여 top@10 추출\n",
    "    sorted_items = sorted(item_scores.items(), key=lambda x: x[1], reverse=True)[:top_k]\n",
    "    for item, _ in sorted_items:\n",
    "        recommendation_list.append({\"user\": user, \"item\": item})\n",
    "\n",
    "# 최종 추천 결과 DataFrame\n",
    "final_recommendations_df = pd.DataFrame(recommendation_list)\n",
    "\n",
    "# 결과 출력\n",
    "print(\"\\nFinal recommendations:\")\n",
    "print(final_recommendations_df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 157,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>user</th>\n",
       "      <th>item</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>11</td>\n",
       "      <td>4886</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>11</td>\n",
       "      <td>8961</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>11</td>\n",
       "      <td>4370</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>11</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>11</td>\n",
       "      <td>32587</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>11</td>\n",
       "      <td>37386</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>11</td>\n",
       "      <td>40815</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>11</td>\n",
       "      <td>7373</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>11</td>\n",
       "      <td>7438</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>11</td>\n",
       "      <td>8861</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>14</td>\n",
       "      <td>1223</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>14</td>\n",
       "      <td>1198</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>14</td>\n",
       "      <td>4016</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>14</td>\n",
       "      <td>914</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>14</td>\n",
       "      <td>4857</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15</th>\n",
       "      <td>14</td>\n",
       "      <td>1035</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16</th>\n",
       "      <td>14</td>\n",
       "      <td>1907</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17</th>\n",
       "      <td>14</td>\n",
       "      <td>2398</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18</th>\n",
       "      <td>14</td>\n",
       "      <td>919</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19</th>\n",
       "      <td>14</td>\n",
       "      <td>1028</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "    user   item\n",
       "0     11   4886\n",
       "1     11   8961\n",
       "2     11   4370\n",
       "3     11      2\n",
       "4     11  32587\n",
       "5     11  37386\n",
       "6     11  40815\n",
       "7     11   7373\n",
       "8     11   7438\n",
       "9     11   8861\n",
       "10    14   1223\n",
       "11    14   1198\n",
       "12    14   4016\n",
       "13    14    914\n",
       "14    14   4857\n",
       "15    14   1035\n",
       "16    14   1907\n",
       "17    14   2398\n",
       "18    14    919\n",
       "19    14   1028"
      ]
     },
     "execution_count": 157,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "final_recommendations_df.head(20)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 158,
   "metadata": {},
   "outputs": [],
   "source": [
    "final_recommendations_df.to_csv(\"./data/output/Ensemble/output_ensemble9.csv\", index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 159,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "93.74298469387755"
      ]
     },
     "execution_count": 159,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df1 = pd.read_csv(\"./data/output/Ensemble/output_ensemble1.csv\")\n",
    "df2 = pd.read_csv(\"./data/output/Ensemble/output_ensemble9.csv\")\n",
    "count_similiarity(df1, df2)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# General: Sequential = 7:3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 139,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_general = pd.read_csv(\"./data/output/Ensemble/output_ensemble7_general.csv\")\n",
    "df_sequential = pd.read_csv(\"./data/output/Ensemble/output_ensemble7_sequential.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 142,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>user</th>\n",
       "      <th>item</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>11</td>\n",
       "      <td>4886</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>11</td>\n",
       "      <td>4370</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>11</td>\n",
       "      <td>8961</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>11</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>11</td>\n",
       "      <td>40815</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>313595</th>\n",
       "      <td>138493</td>\n",
       "      <td>48394</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>313596</th>\n",
       "      <td>138493</td>\n",
       "      <td>8961</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>313597</th>\n",
       "      <td>138493</td>\n",
       "      <td>5349</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>313598</th>\n",
       "      <td>138493</td>\n",
       "      <td>110</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>313599</th>\n",
       "      <td>138493</td>\n",
       "      <td>1022</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>313600 rows × 2 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "          user   item\n",
       "0           11   4886\n",
       "1           11   4370\n",
       "2           11   8961\n",
       "3           11      2\n",
       "4           11  40815\n",
       "...        ...    ...\n",
       "313595  138493  48394\n",
       "313596  138493   8961\n",
       "313597  138493   5349\n",
       "313598  138493    110\n",
       "313599  138493   1022\n",
       "\n",
       "[313600 rows x 2 columns]"
      ]
     },
     "execution_count": 142,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_general"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 150,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 31360/31360 [00:40<00:00, 779.28it/s]\n"
     ]
    }
   ],
   "source": [
    "# 1. CSV 파일 읽기\n",
    "a_csv = pd.read_csv(\"./data/output/Ensemble/output_ensemble7_general.csv\")\n",
    "b_csv = pd.read_csv(\"./data/output/Ensemble/output_ensemble7_sequential.csv\")\n",
    "\n",
    "# 결과 저장용 리스트\n",
    "result = []\n",
    "\n",
    "# 유저 리스트 생성 (a와 b에서 공통 유저)\n",
    "users = a_csv['user'].unique()\n",
    "\n",
    "# 2. 유저별로 아이템 추출\n",
    "for user in tqdm(users):\n",
    "    # a.csv에서 해당 유저의 상위 5개 추출\n",
    "    a_items = a_csv[a_csv['user'] == user]['item'].values[:9]\n",
    "    \n",
    "    # b.csv에서 해당 유저의 아이템 중 a_items를 제외한 상위 5개 추출\n",
    "    b_items = b_csv[b_csv['user'] == user]['item'].values\n",
    "    b_items = [item for item in b_items if item not in a_items][:1]\n",
    "    \n",
    "    # 최종 10개 아이템 (a_items + b_items)\n",
    "    combined_items = list(a_items) + b_items\n",
    "    \n",
    "    # 결과 저장 (user, item) 형식\n",
    "    for item in combined_items:\n",
    "        result.append({'user': user, 'item': item})\n",
    "\n",
    "# 3. 결과를 DataFrame으로 변환\n",
    "final_df = pd.DataFrame(result)\n",
    "\n",
    "# 4. 새로운 CSV 파일로 저장\n",
    "# final_df.to_csv('final_combined.csv', index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 151,
   "metadata": {},
   "outputs": [],
   "source": [
    "final_df.to_csv('data/output/Ensemble/ouput_ensemble8.csv', index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 152,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>user</th>\n",
       "      <th>item</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>11</td>\n",
       "      <td>4886</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>11</td>\n",
       "      <td>4370</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>11</td>\n",
       "      <td>8961</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>11</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>11</td>\n",
       "      <td>40815</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>11</td>\n",
       "      <td>32587</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>11</td>\n",
       "      <td>7373</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>11</td>\n",
       "      <td>47</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>11</td>\n",
       "      <td>37386</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>11</td>\n",
       "      <td>5952</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>14</td>\n",
       "      <td>1198</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>14</td>\n",
       "      <td>1223</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>14</td>\n",
       "      <td>919</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>14</td>\n",
       "      <td>2398</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>14</td>\n",
       "      <td>1907</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15</th>\n",
       "      <td>14</td>\n",
       "      <td>914</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16</th>\n",
       "      <td>14</td>\n",
       "      <td>1035</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17</th>\n",
       "      <td>14</td>\n",
       "      <td>4016</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18</th>\n",
       "      <td>14</td>\n",
       "      <td>4857</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19</th>\n",
       "      <td>14</td>\n",
       "      <td>1022</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "    user   item\n",
       "0     11   4886\n",
       "1     11   4370\n",
       "2     11   8961\n",
       "3     11      2\n",
       "4     11  40815\n",
       "5     11  32587\n",
       "6     11   7373\n",
       "7     11     47\n",
       "8     11  37386\n",
       "9     11   5952\n",
       "10    14   1198\n",
       "11    14   1223\n",
       "12    14    919\n",
       "13    14   2398\n",
       "14    14   1907\n",
       "15    14    914\n",
       "16    14   1035\n",
       "17    14   4016\n",
       "18    14   4857\n",
       "19    14   1022"
      ]
     },
     "execution_count": 152,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "final_df.head(20)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 153,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "78.56983418367346"
      ]
     },
     "execution_count": 153,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df1 = pd.read_csv(\"./data/output/Ensemble/output_ensemble1.csv\")\n",
    "df2 = pd.read_csv(\"./data/output/Ensemble/ouput_ensemble8.csv\")\n",
    "count_similiarity(df1, df2)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
